# -*- coding: utf-8 -*-
"""Copy of Regressors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PW1jyuu5kFB7uasD_BgDwsucQhdtxhsj

# **Regressors** 
Let's Boost Our Knowledge with Regression Problems and be Ready for All of it,


# Important Note :-
While dealing with vectors  [ 1D Array ] =  1 Feature  or 1 Label
Some functions such as fitting and transforming would require the input to be reshaped , try to just add a line  for this  when you want to reshape `X` 
you just type  :-
`X= X.reshape(-1,1)  `
"""

#from google.colab import drive
#drive.mount('/content/drive/')
#import os 
#os.chdir('drive/My Drive/Split3 : Machine Learning')

"""# **First**   : Come and Have A look on a Comparison Between Polynomial Regression and Linear Regression
 
"""

## Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import sklearn
# Importing the dataset
df= pd.read_csv('Salary_Data.csv')
X= df.iloc[:,0].values
y=df.iloc[:,1].values
# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X=X.reshape(-1,1)
y=y.reshape(-1,1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)
# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)
# Fitting Linear Regression to the dataset
from sklearn.tree import DecisionTreeRegressor
Regressor= DecisionTreeRegressor()
Regressor.fit(X,y)
#-------#
#Evaluation
from sklearn.metrics import r2_score
Er1=r2_score(y,Regressor.predict(X))
print('R squared of DecisionTreeRegressor :', Er1)
#Visualising the Linear Regression results
plt.scatter(X, y, color = 'red')
plt.plot(X , Regressor.predict(X), color = 'blue')
plt.title('DecisionTreeRegressor by Sherif Ahmed')
plt.xlabel('Position level')
plt.ylabel('Salary')
plt.show()

help(r2_score)